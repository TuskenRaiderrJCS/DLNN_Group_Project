{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Requirements](#Requirements)\n",
    "2. [Introduction](#Introduction)\n",
    "3. [Imports](#Imports)\n",
    "    1. [Libraries](#Libraries)\n",
    "    2. [Data](#Data)\n",
    "4. [Data Exploration](#data-exploration)\n",
    "5. [Modelling](#modelling)\n",
    "    1. [Baseline](#baseline)\n",
    "    2. [LSTM](#lstm)\n",
    "6. [Results Analysis](#results-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kerastuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import kerastuner as kt\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# Split the data\n",
    "X_train, y_train, X_val, y_val = load_data(hourly_energy_consumption, hourly_temperature, hourly_radiation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui tratar de qualquer operação ou criação de variáveis que sejam\n",
    "# necessárias para o processo de modelação de DL.\n",
    "# Number of samples\n",
    "n_samples = len(hourly_energy_consumption)\n",
    "\n",
    "# Number of time steps\n",
    "n_timesteps = 24\n",
    "# Number of features\n",
    "n_features = 3\n",
    "# Reshape the data into a 3D array to feed the Neural Netwokrs\n",
    "X = np.empty((n_samples, n_timesteps, n_features))\n",
    "X[:, :, 0] = hourly_energy_consumption\n",
    "X[:, :, 1] = hourly_temperature\n",
    "X[:, :, 2] = hourly_radiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "        Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A persistência é o método de baseline mais condiserado e que, como o nome indica, considera que o valor para o futuro é igual à ultima observação. Pode ser denotado pela seguinte equação:\n",
    "\n",
    "$ T_{t+1} = T_{t} $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the persistence matrix\n",
    "# df.merged.shape should be Amount of predictions we want to gather X 24\n",
    "persistence_forecasts=np.zeros((dfmerged.shape),dtype=float)\n",
    "for i in range(len(dfmerged)):\n",
    "    persistence_forecasts.iloc[i,:]=dfmerged.iloc[i,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(24))\n",
    "    \n",
    "    # Choose an optimizer\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'sgd','rmsprop'])\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "    else:    \n",
    "        optimizer = tf.keras.optimizers.RMSprop(\n",
    "            hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "        \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "# Define the search space for Keras Tuner\n",
    "hps = HyperParameters()\n",
    "hps.Choice('batch_size', [32, 64, 128, 256])\n",
    "hps.Choice('activation', ['relu', 'tanh','sigmoid'])\n",
    "# Use the Keras Tuner to search for the best set of hyperparameters\n",
    "tuner = kt.Hyperband(build_model, hps)\n",
    "tuner.search(X_train, y_train, epochs=100,batch_size=1, validation_data=(X_val, y_val))\n",
    "# Get the best model from the search\n",
    "best_model = tuner.get_best_model()\n",
    "# Use the best model to make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee913d83a0c82c8d547cbbd2c0a6f5c15e3a23100419de5e4ed8e88628ce52c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
